{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Spatial Configuration demo\n",
    "\n",
    "This notebook provides a simple demo for 3D Spatial Configuration generatino proposed in our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Import necessary modules and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import trimesh\n",
    "import torch\n",
    "from generate_utils import get_order_obj, get_joints, get_param, point_align_vis, rotate, rotate_mul\n",
    "\n",
    "class Arguments():\n",
    "    def __init__(self, gender, smplx_path):\n",
    "        self.gender     = gender\n",
    "        self.smplx_path = smplx_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "\n",
    "Specify the arguments for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args     = Arguments(gender='male', smplx_path='/disk1/liyonglu/smplify-x/models/smplx/')\n",
    "obj_name = 'keyboard'\n",
    "result   = pickle.load(open('demo/result.pkl', 'rb'))\n",
    "hbox     = pickle.load(open('demo/hbox.pkl', 'rb'))\n",
    "obox     = pickle.load(open('demo/obox.pkl', 'rb'))\n",
    "mesh       = 'demo/human.obj'\n",
    "img        = 'demo/sample.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Generate and save the 3D Spatial Configuration. MeshLab is recommended for visualizing the generated `demo/config.obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hoi, order_obj_list, obj_para_dict = get_order_obj()\n",
    "htri       = trimesh.load(mesh)\n",
    "vertice    = np.array(htri.vertices,dtype=np.float32)\n",
    "joints     = get_joints(args, torch.FloatTensor(torch.from_numpy(vertice.reshape(1,-1,3))))\n",
    "shoulder_len = np.linalg.norm(joints[16] - joints[17])\n",
    "radius    = obj_para_dict[obj_name]['ratio'] * shoulder_len\n",
    "gamma_min = obj_para_dict[obj_name]['gamma_min']\n",
    "gamma_max = obj_para_dict[obj_name]['gamma_max']\n",
    "otri, _   = get_param(result, hbox, obox, htri, img, radius, gamma_min, gamma_max)\n",
    "config    = htri + otri\n",
    "ansp = rotate(joints - joints[0])\n",
    "vertices = np.array(config.vertices)\n",
    "vertices = vertices - joints[0]\n",
    "vertices = rotate_mul(vertices, ansp)\n",
    "config = trimesh.Trimesh(vertices=vertices, faces=config.faces)\n",
    "_ = config.export('demo/config.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reprojection visualization\n",
    "\n",
    "We also provide a simple reprojection visualization for both human and object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_align_vis(result, hbox, 'demo/human.obj', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_align_vis(result, obox, 'demo/object.obj', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
